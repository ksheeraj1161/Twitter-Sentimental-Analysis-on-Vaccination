{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9cd24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # for regular expressions \n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 200) \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk # for text manipulation \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90d92c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (89973, 31)\n",
      "Columns are: Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
      "       'user_id', 'username', 'name', 'place', 'tweet', 'mentions', 'urls',\n",
      "       'photos', 'replies_count', 'retweets_count', 'likes_count', 'hashtags',\n",
      "       'cashtags', 'link', 'retweet', 'quote_url', 'video', 'near', 'geo',\n",
      "       'source', 'user_rt_id', 'user_rt', 'retweet_id', 'reply_to',\n",
      "       'retweet_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/kandr/Downloads/vaccination2.csv\") \n",
    "print ('Dataset size:', df.shape)\n",
    "print ('Columns are:', df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8639e281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>Thinks:  ... tetanus vaccination currently? ...üòâ</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>Forced Vaccination &amp; It's Ties To Eugenics - David Icke  https://youtu.be/TulGwcqeyfE¬† via @YouTube</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>We have had our flu vaccination to protect our patients, staff and families - how u? @MFT_MRI https://twitter.com/l_ebah/status/1179740750508183552¬†‚Ä¶</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>That's true, they are not, which is why there are known contraindications to vaccination. Docs know this stuff.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>Flu vaccination during pregnancy is safe, helps protect mothers from flu during pregnancy, and helps protect babies for several months after birth. This is important since babies under 6 months ca...</td>\n",
       "      <td>['#fluvax']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>What did farmers make of the Badger Vaccination Deployment Project, and have their views changed over time? Our longitudinal analysis is out now.  https://onlinelibrary.wiley.com/doi/10.1111/soru....</td>\n",
       "      <td>['#tbfree', '#badgercull']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>An employee at Turning Stone Resort Casino in Oneida County was diagnosed with infectious hepatitis A last week, forcing the hurried vaccination of some guests and workers  http://bit.ly/2n9DUka¬† ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>#Nigeria: An outbreak of yellow fever is ongoing. Proof of vaccination is required to enter the country. If you travel to the area, consult a health care professional at least 6 weeks before your ...</td>\n",
       "      <td>['#nigeria']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>Impressive numbers! So pleased to continue supporting your teams with their #vaccination skills - brilliant result guys already!! Keeping your #communities protected üëçüíâ https://twitter.com/daylewi...</td>\n",
       "      <td>['#vaccination', '#communities']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>‚Å¶@DrBGellin‚Å© @Sabin urging more #research at the interface of #vaccines and #AntibioticResistance at the ‚Å¶@EU_Health‚Å© Joint Action on Vaccination Summit in #Rome #VaccinesWork pic.twitter.com/H6RH...</td>\n",
       "      <td>['#research', '#vaccines', '#antibioticresistance', '#rome', '#vaccineswork']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  \\\n",
       "0  2019-10-03   \n",
       "1  2019-10-03   \n",
       "2  2019-10-03   \n",
       "3  2019-10-03   \n",
       "4  2019-10-03   \n",
       "5  2019-10-03   \n",
       "6  2019-10-03   \n",
       "7  2019-10-03   \n",
       "8  2019-10-03   \n",
       "9  2019-10-03   \n",
       "\n",
       "                                                                                                                                                                                                     tweet  \\\n",
       "0                                                                                                                                                         Thinks:  ... tetanus vaccination currently? ...üòâ   \n",
       "1                                                                                                      Forced Vaccination & It's Ties To Eugenics - David Icke  https://youtu.be/TulGwcqeyfE¬† via @YouTube   \n",
       "2                                                    We have had our flu vaccination to protect our patients, staff and families - how u? @MFT_MRI https://twitter.com/l_ebah/status/1179740750508183552¬†‚Ä¶   \n",
       "3                                                                                          That's true, they are not, which is why there are known contraindications to vaccination. Docs know this stuff.   \n",
       "4  Flu vaccination during pregnancy is safe, helps protect mothers from flu during pregnancy, and helps protect babies for several months after birth. This is important since babies under 6 months ca...   \n",
       "5  What did farmers make of the Badger Vaccination Deployment Project, and have their views changed over time? Our longitudinal analysis is out now.  https://onlinelibrary.wiley.com/doi/10.1111/soru....   \n",
       "6  An employee at Turning Stone Resort Casino in Oneida County was diagnosed with infectious hepatitis A last week, forcing the hurried vaccination of some guests and workers  http://bit.ly/2n9DUka¬† ...   \n",
       "7  #Nigeria: An outbreak of yellow fever is ongoing. Proof of vaccination is required to enter the country. If you travel to the area, consult a health care professional at least 6 weeks before your ...   \n",
       "8  Impressive numbers! So pleased to continue supporting your teams with their #vaccination skills - brilliant result guys already!! Keeping your #communities protected üëçüíâ https://twitter.com/daylewi...   \n",
       "9  ‚Å¶@DrBGellin‚Å© @Sabin urging more #research at the interface of #vaccines and #AntibioticResistance at the ‚Å¶@EU_Health‚Å© Joint Action on Vaccination Summit in #Rome #VaccinesWork pic.twitter.com/H6RH...   \n",
       "\n",
       "                                                                        hashtags  \n",
       "0                                                                             []  \n",
       "1                                                                             []  \n",
       "2                                                                             []  \n",
       "3                                                                             []  \n",
       "4                                                                    ['#fluvax']  \n",
       "5                                                     ['#tbfree', '#badgercull']  \n",
       "6                                                                             []  \n",
       "7                                                                   ['#nigeria']  \n",
       "8                                               ['#vaccination', '#communities']  \n",
       "9  ['#research', '#vaccines', '#antibioticresistance', '#rome', '#vaccineswork']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#considering only the date, tweet and hashtags\n",
    "df = df.drop(columns=['id', 'time','user_id','username','conversation_id','created_at','timezone', 'name', 'place', 'mentions', 'urls', 'photos', 'replies_count', 'likes_count', 'cashtags', 'link',\n",
    "'retweet','retweets_count', 'quote_url', 'video', 'near', 'geo', 'source', 'user_rt_id', 'user_rt', 'retweet_id', 'reply_to', 'retweet_date'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6c74c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (89973, 3)\n",
      "Columns are: Index(['date', 'tweet', 'hashtags'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89973 entries, 0 to 89972\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   date      89973 non-null  object\n",
      " 1   tweet     89973 non-null  object\n",
      " 2   hashtags  89973 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print ('Dataset size:',df.shape) \n",
    "print ('Columns are:',df.columns) \n",
    "df.info ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92ce0f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89973 entries, 0 to 89972\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date      89973 non-null  datetime64[ns]\n",
      " 1   tweet     89973 non-null  object        \n",
      " 2   hashtags  89973 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 2.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8997 entries, 62925 to 77106\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date      8997 non-null   datetime64[ns]\n",
      " 1   tweet     8997 non-null   object        \n",
      " 2   hashtags  8997 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 281.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df[\"tweet\"] = df[\"tweet\"].astype(str)\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True) \n",
    "df.info ()\n",
    "df = df.sample(frac=.1, random_state=1111) \n",
    "df.info ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb429d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import re\n",
    "MIN_YEAR = 1900\n",
    "MAX_YEAR = 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab0c364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_patern():\n",
    "    return re.compile( r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))' r'[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0- 9]\\.[^\\s]{2,})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4894e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emojis_pattern(): \n",
    "\n",
    "    try:\n",
    "# UCS-4\n",
    "        emojis_pattern = re.compile(u'([\\U00002600 \\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
    "    except re.error:\n",
    "# UCS-2\n",
    "        emojis_pattern = re. compile(u'([\\u2600-\\u27BF])|([\\uD83C][\\uDF00-\\uDFFF])|([\\uD83D][\\uDC00-\\uDE4F])|([\\uD83D][\\uDE80-\\uDEFF])')\n",
    "    return emojis_pattern\n",
    "\n",
    "def get_hashtags_pattern():\n",
    "    return re.compile(r'#\\w*')\n",
    "\n",
    "def get_single_letter_words_pattern():\n",
    "    return re.compile(r'(?<![\\w\\-])\\w(?![\\w\\-])')\n",
    "\n",
    "def get_blank_spaces_pattern():\n",
    "    return re.compile(r'\\s{2,}|\\t')\n",
    "\n",
    "def get_twitter_reserved_words_pattern():\n",
    "    return re.compile(r'(RT|rt|FAV|fav|VIA|via)')\n",
    "\n",
    "def get_mentions_pattern():\n",
    "    return re.compile(r'@\\w*')\n",
    "\n",
    "def is_year(text):\n",
    "    if (len(text) == 3 or len(text) == 4) and (MIN_YEAR < len(text) < MAX_YEAR): \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e686c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterPreprocessor:\n",
    "    def init (self, text: str): \n",
    "        self.text = text\n",
    "    def fully_preprocess(self): \n",
    "        return self \\\n",
    "            .remove_urls() \\\n",
    "            .remove_mentions() \\\n",
    "            .remove_hashtags() \\\n",
    "            .remove_twitter_reserved_words() \\\n",
    "            .remove_punctuation() \\\n",
    "            .remove_single_letter_words() \\\n",
    "            .remove_blank_spaces() \\\n",
    "            .remove_stopwords() \\\n",
    "            .remove_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e82ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the pattern is found replace it with whatever is in repl or else return the same string \n",
    "def remove_urls(self):\n",
    "    self.text = re.sub(pattern=get_url_patern(), repl='', string=self.text) \n",
    "    return self\n",
    "    def remove_punctuation(self):\n",
    "        self.text = self.text.translate(str.maketrans('', '', string.punctuation)) \n",
    "        return self\n",
    "    def remove_mentions(self):\n",
    "        self.text = re.sub(pattern=get_mentions_pattern(), repl='', string=self.text) \n",
    "        return self\n",
    "    def remove_hashtags(self):\n",
    "        self.text = re.sub(pattern=get_hashtags_pattern(), repl='', string=self.text) \n",
    "        return self\n",
    "    def remove_twitter_reserved_words(self):\n",
    "        self.text = re.sub(pattern=get_twitter_reserved_words_pattern(), repl='', string=self.text)\n",
    "        return self\n",
    "    def remove_single_letter_words(self):\n",
    "        self.text = re.sub(pattern=get_single_letter_words_pattern(), repl='', string=self.text)\n",
    "        return self\n",
    "\n",
    "    def remove_blank_spaces(self):\n",
    "        self.text = re.sub(pattern=get_blank_spaces_pattern(), repl=' ', string=self.text) \n",
    "        return self\n",
    "    \n",
    "    def remove_stopwords(self, extra_stopwords=None): \n",
    "        if extra_stopwords is None:\n",
    "            extra_stopwords = []\n",
    "        text = nltk.word_tokenize(self.text)\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "        new_sentence = []\n",
    "        for w in text:\n",
    "            if w not in stop_words and w not in extra_stopwords: \n",
    "                new_sentence.append(w)\n",
    "            self.text = ' '. join(new_sentence) \n",
    "            return self\n",
    " \n",
    "    def remove_numbers(self, preserve_years=False): \n",
    "        text_list = self.text.split(' ')\n",
    "        for text in text_list:\n",
    "            if text.isnumeric():\n",
    "                if preserve_years:\n",
    "                    if not is_year(text):\n",
    "                        text_list.remove(text)\n",
    "                else:\n",
    "                    text_list.remove(text)\n",
    "        self.text = ' '. join(text_list) \n",
    "        return self\n",
    "    def lowercase(self):\n",
    "        self.text = self.text.lower() \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa5eee7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TwitterPreprocessor() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-ecdc9b4f948b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclean_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwitterPreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfully_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: TwitterPreprocessor() takes no arguments"
     ]
    }
   ],
   "source": [
    "# Clean tweets and append to new column \n",
    "tweets = df['tweet']\n",
    "clean_tweets = [] \n",
    "for tweet in tweets:\n",
    "    c = TwitterPreprocessor((tweet)) \n",
    "    c.fully_preprocess()\n",
    "    c = c.text\n",
    "    clean_tweets.append(c)\n",
    "\n",
    "df['clean_tweets'] = clean_tweets \n",
    "df.head(5)\n",
    "\n",
    "all_words = ' '.join([text for text in df['clean_tweets']]) \n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, \n",
    "                      max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\") \n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# create analyzer object\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# get a list of scores and plot\n",
    "scores = [analyzer.polarity_scores(tweet)['compound'] for tweet in df['clean_tweets']] \n",
    "plt.hist(scores, bins=20)\n",
    "\n",
    "sentiment = df['clean_tweets'].apply(lambda x: analyzer.polarity_scores(x)) \n",
    "df = pd.concat([df,sentiment.apply(pd.Series)],1)\n",
    " \n",
    "df.head(5) \n",
    "df.describe()\n",
    "df.index = pd.to_datetime(df['date']) \n",
    "df = df.sort_index()\n",
    "df['mean'] = df['compound']. expanding (). mean ()\n",
    "df['rolling'] = df['compound']. rolling('1d'). mean ()\n",
    "\n",
    "import datetime as dt\n",
    "fig = plt.figure(figsize=(20,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(df['date'],df['compound'], label='Tweet Sentiment') \n",
    "ax.plot(df['date'],df['rolling'], color ='r', label='Rolling Mean') \n",
    "ax.plot(df['date'],df['mean'], color='g', label='Expanding Mean')\n",
    "\n",
    "\n",
    "ax.set(title='Vaccination Tweets over Time', xlabel='Date', ylabel='Sentiment') \n",
    "ax.legend(loc='best')\n",
    "fig.tight_layout() \n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    horizontalalignment='right', \n",
    "    fontweight='light',\n",
    "    fontsize='x-large'\n",
    ")\n",
    "plt.show()\n",
    "fig = plt.figure(figsize=(10,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.set(title='Vaccination Tweets Sentiment Score', xlabel='Compund Sentiment Score', \n",
    "ylabel='Frequency')\n",
    "sns.distplot(df['compound'], bins=15, ax=ax) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d9616bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'compound'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'compound'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-e84c035fdf7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mexpanding\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rolling'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mrolling\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'1d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'compound'"
     ]
    }
   ],
   "source": [
    "#Reduce noise\n",
    "ot = df.sample(frac=.05, random_state=1111) \n",
    "ot.sort_index(inplace=True)\n",
    "ot['mean'] = ot['compound']. expanding (). mean ()\n",
    "ot['rolling'] = ot['compound']. rolling ('1d'). mean() \n",
    "fig = plt.figure(figsize=(30,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(ot['date'],ot['compound'], label='Tweet Sentiment') \n",
    "ax.plot(ot['date'],ot['rolling'], color ='r', label='Rolling Mean') \n",
    "ax.plot(ot['date'],ot['mean'], color='g', label='Expanding Mean')\n",
    "ax.set(title='Vaccination Tweets over Time', xlabel='Date', ylabel='Sentiment') \n",
    "ax.legend(loc='best')\n",
    "fig.tight_layout() \n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    horizontalalignment='right', \n",
    "    fontweight='light',\n",
    "    fontsize='x-large'\n",
    " \n",
    ")\n",
    "plt.show()\n",
    "\n",
    "def hashtag_extract(x):\n",
    "    hashtags = []\n",
    "    # Loop over the words in the tweet \n",
    "    for i in x:\n",
    "        ht = re.findall(r\"#(\\w+)\", i) \n",
    "        hashtags.append(ht)\n",
    "    return hashtags\n",
    "\n",
    "# extracting hashtags from neutral tweets\n",
    "HT_neutral = hashtag_extract(df['hashtags'][df['compound'] == 0])\n",
    "\n",
    "# extracting hashtags from negative tweets\n",
    "HT_negative = hashtag_extract(df['hashtags'] [df['compound'] < 0])\n",
    "\n",
    "# extracting hashtags from positive tweets\n",
    "HT_positive = hashtag_extract(df['hashtags'] [df['compound'] > 0])\n",
    "\n",
    "# unnesting list\n",
    "HT_neutral = sum (HT_neutral,[]) \n",
    "HT_negative = sum (HT_negative,[]) \n",
    "HT_positive = sum (HT_positive,[]) \n",
    "a = nltk.FreqDist(HT_neutral)\n",
    "d = pd.DataFrame({'Hashtag': list(a.keys()), 'Count': list(a.values())})\n",
    "\n",
    "# selecting top 20 most frequent hashtags\n",
    "d = d.nlargest(columns=\"Count\", n = 20) # nlargest returns the first n rows ordered by columns in descending order.\n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\") \n",
    "ax.set(ylabel = 'Count')\n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    horizontalalignment='right', \n",
    "    fontweight='light',\n",
    "    fontsize='x-large'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "#extracting hashtags from negative tweets \n",
    "b = nltk.FreqDist(HT_negative)\n",
    "e = pd.DataFrame({'Hashtag': list(b.keys()), 'Count': list(b.values())})\n",
    "\n",
    "# selecting top 20 most frequent hashtags \n",
    "e = e.nlargest(columns=\"Count\", n = 20) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=e, x= \"Hashtag\", y = \"Count\") \n",
    "ax.set(ylabel = 'Count')\n",
    " \n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    horizontalalignment='right', \n",
    "    fontweight='light',\n",
    "    fontsize='x-large'\n",
    ")\n",
    "plt.show()\n",
    "c = nltk.FreqDist(HT_positive)\n",
    "f = pd.DataFrame({'Hashtag': list(c.keys()), 'Count': list(c.values())})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# selecting top 20 most frequent hashtags \n",
    "f = f.nlargest(columns=\"Count\", n = 20) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=f, x= \"Hashtag\", y = \"Count\") \n",
    "ax.set(ylabel = 'Count')\n",
    "plt.xticks(\n",
    "    rotation=45,\n",
    "    horizontalalignment='right', \n",
    "    fontweight='light',\n",
    "    fontsize='x-large'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b2ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
